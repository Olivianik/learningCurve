34
To get rid of your data, you can simply load the database you want to get rid of (use databaseName) and then execute db.dropDatabase().
Similarly, you could get rid of a single collection in a database via db.myCollection.drop().

35
show dbs
show collections

36
mongodb does not enforce any schemas, your documents can look the way you want and you can have totally different documents in one and the same collection.
db.products.insertOne({name: 'A book', price: 12.99})
db.products.insertOne({title: 'T-Shirt', seller: {name: 'Max', age: 29}})
mongodb will not complain about different schema.
We get totally different structures or schemas as you could call it in one and the same collection and that is fine.
Schema simply means the structure of one document, how does it look like, which fields does it have, which types of values do these fields have.
In reality, you will probably have some kind of schema because if you are building the backend for your online shop, it's in your interest that all your products have a price.
you will most likely have some kind of schema because you as a developer want it because your application needs it.

37
db.products.deleteMany({})
db.products.insertOne({name: 'A book', price: 12.99})
db.products.insertOne({name: 'A T-Shirt', price: 20.99})
This is the case on the right, the SQL world, we got exactly the same structure, just the values differ.
db.products.insertOne({name: 'A Computer', price: 1299, details: {cpu: 'Intel i7 8770'}})
If I add this and now I find all my documents, we are in the middle world.
Generally we have the same though, name and price but then we get some extra information on one product.
That might be something that works for your application too because there.
You could of course have some code which always displays the name and the price but only displays the details if available.
Therefore we can reflect this in our data and we now are in that middle column of the last slide.
We got a core structure which every document fulfills, like a name and a price exists on every document.
A little side note here is that the price actually does not always have the same kind of data.
It looks like it always has a number and that is true but we switch between a double number.
So number with decimal places and an integer, a number without decimal places.
db.products.deleteMany({})
db.products.insertOne({name: 'A book', price: 12.99, details: null})
db.products.insertOne({name: 'A T-Shirt', price: 20.99, details: null})
db.products.insertOne({name: 'A Computer', price: 1299, details: {cpu: 'Intel i7 8770'}})
Null is a value which you can assign to indicate that well there is no value but there is the field available then.
db.products.find().pretty()
That is the more SQL-ish approach I'd say because the structure is now exactly equal in all documents.
Except for that number thing which I mentioned, the price is a different type of number.
But otherwise it's exactly the same structure.
This might also be an approach you use because you like the clarity of having exactly the same fields everywhere.
Simply indicate that no value is available by setting the value to null.
Now here you can take either approach,
It's probably a bit more MongoDB-ish to simply get rid of details if it holds no value.
Ultimately this is also up to you and you could take this route too, there is no single best practice here.
You can go with whichever approach works better for you or whichever approach you personally prefer.

38
In the shell by the way if you just enter a normal value, it is treated as a float value.
that is because the normal shell as we use it in the course is based on javascript and javascript doesn't differentiate between integers and floating point values.
So values with a decimal place, therefore everything will be stored as a 64bit float value in the shell, that is the default value.
objectId object is a special object automatically generated by mongodb to give you a unique ID which is not just a unique random string but also a string that contains a temporal component.
so that if you create two elements after each other, two documents after each other, you are guaranteed to have the right order due to that ID.
because the older element will have an ID that comes prior to the other one, so there is this sorting built into the objectId because it respects a timestamp.
There also is a timestamp type, the timestamp is mostly used internally.
You can create it automatically, mostly you let mongodb create that for you and that is guaranteed to be unique too.
So even if you create two documents at the same time, they will not have exactly the same timestamp.
Because it will basically take into account the current time and then also add an ordinal value, so that two documents at the same time still don't get the same timestamp.
But respect the order in which the insert command was issued for example.

39
use companyData
db.companies.insertOne({name: 'Fresh Apple Inc', isStartup: true, employees: 33, funding: 12345678901234567890, details: {ceo: 'Mark Super'}, tags: [{title: 'super'}, {title: 'perfect'}], foundingDate: new Date(), insertedAt: new Timestamp()})
https://www.mongodb.com/docs/drivers/node/current/
https://mongodb.github.io/node-mongodb-native/4.7/
https://mongodb.github.io/node-mongodb-native/4.7/modules.html
https://mongodb.github.io/node-mongodb-native/4.7/classes/Timestamp.html
db.numbers.insertOne({a: 1})
db.numbers.findOne()
db.stats()
db.stats, stats is a utility method provided by the shell which outputs some well, stats about this database.
Here we see like how many collections we got in there, how many objects and we also see the average object size.
db.companies.drop()
db.stats()
db.numbers.deleteMany({})
db.stats()
db.numbers.insertOne({a: NumberInt(1)})
db.stats()
You could consider using these special values provided by mongodb because you're able to manage your data size a bit more efficiently.
typeof db.numbers.findOne().a
You can also check the type of a value as it is stored in mongodb by using the type of command which is provided in the shell.

40
MongoDB has a couple of hard limits - most importantly, a single document in a collection (including all embedded documents it might have) must be <= 16mb.
Additionally, you may only have 100 levels of embedded documents.
https://www.mongodb.com/docs/manual/reference/limits/
https://www.mongodb.com/docs/manual/reference/bson-types/
Important data type limits are:
Normal integers (int32) can hold a maximum value of +-2,147,483,647
Long integers (int64) can hold a maximum value of +-9,223,372,036,854,775,807
Text can be as long as you want - the limit is the 16mb restriction for the overall document
It's also important to understand the difference between int32 (NumberInt), int64 (NumberLong) and a normal number as you can enter it in the shell. The same goes for a normal double and NumberDecimal.
NumberInt creates a int32 value => NumberInt(55)
NumberLong creates a int64 value => NumberLong(7489729384792)
If you just use a number (e.g. insertOne({a: 1}), this will get added as a normal double into the database. 
The reason for this is that the shell is based on JS which only knows float/ double values and doesn't differ between integers and floats.
NumberDecimal creates a high-precision double value => NumberDecimal("12.99") => This can be helpful for cases where you need (many) exact decimal places for calculations.
When not working with the shell but a MongoDB driver for your app programming language (e.g. PHP, .NET, Node.js, ...), you can use the driver to create these specific numbers.

41
mongodb really embraces that idea of planning your data structure based on the way you'll retrieve your data, so that you don't have to do complex joins
but that you can retrieve your data in the format or almost in the format you need it in your application.

43
This is a one-to-one relation because the summary of patient A can never belong to patient B and the other way around.
use hospital
db.patients.insertOne({name: 'Max', age: 29, diseaseSummary: 'summary-max-1'})
db.diseaseSummaries.insertOne({_id: 'summary-max-1', diseases: ['cold', 'broken leg']})
db.patients.findOne()
db.patients.findOne().diseaseSummary
var dsid = db.patients.findOne().diseaseSummary
dsid
db.diseaseSummaries.findOne({_id: dsid})
db.patients.deleteMany({})
The better approach in such a case where we have a strong one-to-one relation would be to use embedded document.
db.patients.insertOne({name:'Max', age: 29, diseaseSummary: {disease: ['cold', 'broken leg']}})
The huge advantage of course is that in the application we're writing with whichever language we use, I can simply write my query to find my patient by ID.
By name or in this case as a shortcut, simply with findOne and I will get all the data I need, the patient data and the diseaseSummary data.
So this is an example for when you would use an embed document, you have a strong one-to-one relationship.
db.patients.findOne()

44
Now for many, probably most one-to-one relationships, you'll probably go with the embedded document but you're not forced to.
You could also have one-to-one relationships where you still opt to use different collections.
So we have a one-to-one relation then, one car per person and one person per car.
use carData
db.persons.insertOne({name: 'Max', car: {model: 'BMW', price: 40000}})
Use case where we are very interested in analyzing person data like average salary or age.
We're interested in analyzing our persons and we might be interested in analyzing our cars but not so much in a relation.
That might occasionally be interesting too but maybe we also want to do a lot of averaging, a lot of analytics on the persons or the cars.
So here we have an application driven reason for splitting this up, there is no hard reason.
Its perfectly fine theoretically to merge that into one collection as we are currently doing it.
But due to our application needs, this might not be optimal because if we only interested in the cars, there is no need to fetch all the persons just to get to their cars.
That would actually means we have to do a lot of transformation work to extract the car data and we send a lot of unnecessary data over the wire.
db.persons.deleteMany({})
db.persons.insertOne({name: 'Max', age: 29, salary: 3000})
db.cars.insertOne({model: 'BMW', price: 4000, owner: ObjectId("62c18cccd1d2958fc09fa82c")})
So now we still have the possibility to relate the car to an owner.
We could now also store the ID of the car if we wanted to depending on whether we often will have fetched persons and now also want to get the car or the other way around.
We got some link, that is they key take away so we can merge the data if we want to but if we commonly don't do that, we don't have to use an embedded document, we can go for different collections here.
So that would be one possible use case where you use different collections even though you could perfectly embed it.

45
We have question threads and each question thread then has a couple of answers, so an answer only belongs to one thread but a thread can have multiple answers.
That's a typical one-to-many relationship.
use support
db.questionThreads.insertOne({creator: 'Max', question: 'How does that all work?', answer: ['q1a1', 'q1a2']})
db.questionThreads.findOne()
db.answers.insertMany([{_id: 'q1a1', text: 'It works like that.'}, {_id: 'q1a2', text: 'Thanks!.'}])
db.answers.find().pretty()
db.questionThreads.deleteMany({})
db.questionThreads.insertOne({creator: 'Max', question: 'How does that all work?', answer: [{text: 'Like That.'}, {text: 'Thanks!'}]})
db.questionThreads.findOne()
Well then we see now we have that embedded approach, now a list of embedded documents because it's a one-to-many relationship.
We have many documents but still it's embedded documents.
Which we're using here and for a scenario like this and a similar scenario for example would be posts and comments related to posts makes sense to be modelled like this.
Because often, you need to fetch the questions along with the answers, so from application requirement perspective, you want to fetch the merged data.
And we also don't have thousands of answers on one thread typically.
So we also don't have the danger of bloating our document and maybe reaching that 16mb limit we have for a document.
So that is not a problem here and therefore this might be a perfect use case for embedding documents in a one-to-many relationship.

46
Now that we had a look at a one-to-many relationship where embedding made sense.
Let's have a look at a relationship, a one-to-many relationship where splitting it in collections might make sense.
A collection which holds all the major cities of the world and then a list of every person living in that city.
Like the registry of the state where all people are registered.
Theoretically that would make sense to be a one-to-many relationship where you embed your documents.
But for one from application perspective, you might often be interested in fetching all the cities with their metadata.
But you don't want to fetch all the citizens along with the cities because in New York where we have like millions of people.
That would be a lot of overhead data which we don't need which takes very long to fetch and which is a lot of data to transfer over the wire.
And additionally for big cities with millions of citizens, you might indeed hit this 16mb limit for the overall document.
Keep in mind, that limit counts towards a document in nested documents.
It's not 16mb per nested element, it's 16mb for the overall document.
You might face this limit too or might hit this limit too.
For technical and application reasons, here splitting it up might make sense.
use cityData
db.cities.insertOne({name: 'New York City', coordinates: {lat: 21, lng: 55}})
db.cities.findOne()
db.citizens.insertMany([{name: 'Max', cityId: ObjectId("62c1cc9bd1d2958fc09fa830")}, {name: 'Fidya Rosa', cityId: ObjectId("62c1cc9bd1d2958fc09fa830")}])
db.citizens.find().pretty()
Now I can always retrieve just as citizens and match them to their city with the city ID if I need to or fetch just the cities.
I'll not hit the document limitation of 16mb for the city.
Because I don't embed all my citizens and I also don't unnecessarily fetch all the citizens along with the city if I'm only interested in the city metadata.

47
So let's say we have customers who can buy products, so we're looking at orders.
A customer might buy multiple products and a product might be bought by different customers.
One customer many products, one product many customers.
So this is a typical many-to-many relationship, how could we model that?
To say it right away, often you'll model many-to-many relationships with references.
db.products.insertOne({title: 'A Book', price: 12.99})
db.customers.insertOne({name: 'Max', age: 29})
db.orders.insertOne({productId: ObjectId("62c1cf61d1d2958fc09fa833"), customerId: ObjectId("62c1cf8cd1d2958fc09fa834")})
This would be the SQL world approach where we have three tables in SQL and we have that join table in the middle which matches products and customers.
Now we can do a bit better in quotation marks in mongodb, we can make it work with two tables only, so I can actually drop my orders collection.
db.orders.drop()
db.products.find()
db.customers.find()
Typically, I want to add that relation on the customer because you could say yes the product got bought.
But actually customer is the active person and it's more realistic that you're fetching the orders for a given customer than that you want to display orders for a given product.
But that would be possible too and you can use that approach on both tables here.
db.customers.updateOne({}, {$set: {orders: [{productId: ObjectId("62c1cf61d1d2958fc09fa833"), quantity: 2}]}})
db.customers.find()
We're still using a reference approach here because we did not embed the product data.
We just added some metadata for the order but I'm just referencing the product data.
So we're using a reference driven approach here and we could add the same orders array to the products if we want to match it the other way around too.
Both is possible or either of the one like we have it here.
So now we have a many-to-many relationship with references, with two tables which would be the mongodb way of displaying or creating such a many-to-many relationship with references.
You could also argue that you don't necessarily need to use references here.
Often you will and if that's your use case, it's fine but let's have a look at the embedded alternative and for that.
db.customers.updateOne({}, {$set: {orders: [{title: 'A Book', price: 12.99, quantity: 2}]}})
db.customers.find()
Now if I look into my customers collection, we do have an embedded document, this is now not a reference driven approach but I embedded the product data along with the metadata for the order.
A disadvantage is the data duplication.
We've got the title and price of that product in orders here and keep in mind that this user might order this product multiple times and other users could do.
So you will probably duplicate this data a lot and if you ever change that data, you not only need to change it in the products collection where you store it.
That is the product data which is displayed in your shop for users to buy it but you would also have to change it in all the orders, well or do you?
And that is the reason why such an embedded approach might be fine.
Once the order was placed, even if the price changed for the product, we will not change it for the existing orders right?
The people don't have to pay more after they bought it, so the price here is logged in anyways.
The title might change a bit but do we really care about this in our orders?
We might not care, it's not going to change from a book to a T-shirt because it's still the same product in the end.
It still has its own unique ID and we would probably also store the ID along with the product here by the way. 
So probably we don't care about a title change too because if it's a nice book now instead of a book, doesn't really matter for us.
So if we have an application where we kind of take a snapshot of the data anyways, we might not worry too much about duplicating that data.
Because we might not need to change it in all the places where we did duplicate it.
If the original data changes and that of course highly depends on your application.
For a shop and the products and the orders, this might make sense, in other use cases you might absolutely need the latest data everywhere and we'll have a look at such a use case next.
But I want you to not automatically say many-to-many, I will use a reference.
Instead think about how do you fetch your data, how often do you change it and if you change it, do you need to change it everywhere or might duplicates be fine?

48
We had a look at a many-to-many relationship where changing data might not be that bad for our duplicates and therefore embedding the documents might be fine.
Now let's have a look at a many-to-many relationship where splitting it up and using references might be better.
Here we got a couple of books and a couple of authors and one book can be written by multiple authors and one author will probably write more than one book, so it's a typical many-to-many relationship.
Here let's first of all go for the embedded approach.
use bookRegistry
db.books.insertOne({name: 'My favorite Book', authors: [{name: 'Max', age: 29}, {name: 'Rezi', age: 25}]})
db.books.find().pretty()
db.authors.insertMany([{name: 'Max', age: 29, address: {street: 'Main'}}, {name: 'Rezi', age: 25, address: {street: 'Tree'}}])
db.authors.find().pretty()
The problem is if one author changes, maybe I got older, maybe I moved, then I need to update that everywhere where I use that.
And that's not just the authors collection but that would be all my books.
That is especially important let's say if I changed my name because I married, then I can't say now I don't care it's an old snapshot like we did for the orders.
For the books and for the authors, I want to have the most recent data of course.
And if I'm displaying the age in the book, I might say that is a snapshot data, that is ok, for the name it's probably not.
And in my registry in the database even the age is not ok, that should be all up-to-date for future books, for future prints, let's say.
So here, if we then change the name of the author, we have to change it here with the update method in the authors collection.
And we also have to change it in the books collection by finding all books where this author is an author.
And that is a lot of work and a lot of write and update requests.
This is bad from a performance perspective because we have to well write a lot to the database, it also is error prone because we might be overlooking some document we should update.
Therefore, this is probably not the best approach for this scenario because in our application, if the data does change, it should change everywhere.
Now even with that, it might be ok if changes are very unlikely to happen but some data like the age will change at least once a year.
Other data might change more frequently and the more frequent we can expect such changes, the more often we'll have to touch dozens or one hundreds of documents.
So the worse the matter gets.
So low frequency might still let us get away with this approach and might make it a good approach.
With higher frequency, it almost most certainly is not a good way of relating this.
So instead of using embedded documents here, we should go for the reference approach.
db.books.updateOne({}, {$set: {authors: [ObjectId("62c1da38d1d2958fc09fa837"), ObjectId("62c1da38d1d2958fc09fa838")]}})
db.books.findOne()
Now we only got the references in there and this is better.
Because now if we do fetch all the books we will have to merge it manually with the author data but therefore.
But the author data is guaranteed to be up-to-date and if we change the author data.
We don't have to do that in hundreds or thousands of documents.

50
Mongodb offers for merging related documents that you split up by using the reference approach.
So where you got no embedded documents and that is the lookup operator. 
db.books.aggregate([{$lookup: {from: 'authors', localField: 'authors', foreignField: '_id', as: 'creators'}}])
This mitigates some of the disadvantages of splitting your documents across collections because now you can at least merge them in one go.
This uses the so-called aggregation framework.
There you pass an array because you can define multiple steps on how to aggregate your data.
For now there is only one step I'm interested, a step is simply a document you pass to the array that is the lookup step, $lookup.
That step is configured by passing a document as a value and here you need to define four things.
From which other collection do you want to relate documents?
Where can the references to the other collection be found in?
That is the name of the collection where your related documents live in. You then define the local field.
Which field are you relating to in your target collection?
So in the author collection here, the authors collection and you define that with the foreign field key.
Last but not least, you give this an alias under which this will be merged and I'll name this creators, the name is up to you here.
db.books.aggregate([{$lookup: {from: 'authors', localField: 'authors', foreignField: '_id', as: 'creators'}}]).pretty()
What we see here is we get our book, actually all the books we have in there, only one in our case with the name with the authors and the objectIDs.
But then a new key was added, creators and that actually holds the author data which lived in a different collection and which was merged into a result by the aggregate and the lookup function.
So this is very useful for merging data in one step and it allows you to get the best of both worlds, having it split up and still fetching it in one go.
Now this still is not an excuse for always using references because obviously this costs more performance than having an embedded document.
So if you can and if your application needs it, go for an embedded document.
If you have to use references or if you want to use references, well then this lookup step in the aggregate method can at least help you get the data you need.

51
Well a user can create a post and of course edit and delete it then, a user can also comment a post.
So a post can have multiple comments where each comment also knows which user created the comment.
These are the general relations we have in there, how could we now model that?
Well we got the whole variety of things, we could embed everything, we could go with one collection only.
Let's say the post collection is our only collection I want to go with it and in posts, we then have our user and that is an embedded document which holds the user data as defined here.
And in post, we also have our comments which is basically an array of nested documents, here we would have that comment data in array.
So this would be the only collection we then have, posts with embedded users in a single post or the embedded user and embedded comments.
Now is that a good approach?
I don't think that is a good idea.
Nesting the user doesn't sound too good to me because if we nest a user here, then we have a problem because one user can create many posts.
So if the user data then changes, let's say if the e-mail changes, we have to edit that user in all the posts.
So we've got a lot of duplicate data and whilst that might not change on a daily basis, it certainly is not like a user never changes any data.
So it's not such a low frequency that I would be fine with doing all these duplicate changes when they occur.
I'm a fan of actually creating two collections here.
the users collection and the post collection, we'll not have a comment collection, we'll have comment data in this structure, in our array here.
But we'll not have a separate collection for comments.
Instead we'll have have posts and users and we'll use these collections with some embedded documents for comments and also for tags by the way,
Tags also in the end is just an just an array of strings so we could also say that this is a relation to different tags.
So we have two major collections, posts and users.

52
use blog
db.users.insertMany([{name: 'Max', age: 29, email: 'max@test.com'}, {name: 'Rezi', age: 25, email: 'rezi@test.com'}])
db.users.find().pretty()
db.posts.insertOne({title: 'My first post!', text: 'This is my first post, i hope you like it!', tags: ['new', 'tech'], creator: ObjectId("62c28f36d1d2958fc09fa83a"), comments: [{text: 'I like this post!', author: ObjectId("62c28f36d1d2958fc09fa839")}]})
db.posts.findOne()
This is how our blog could look like in code, so in the database.
I also explained why I would structure it like this and this example together with the previous lectures.
Hopefully gets you into the right mental model on how to think about this.
Hopefully helps you with your next projects to structure your data and your relations in a way that makes sense.
For your application to your size of data, the amount of data, the frequency with which you change it and your overall structure or relation that is imposed on to you by your application.

53
Sometimes you want to lock down your flexibility here, you want to get rid of it.
Sometimes you need a strict schema because you know your application is going to fetch posts and it is going to access the title on each post.
And it does expect that each title is a string and for cases like this, schema validation can help you.
Now what is schema validation?
The schema will validate or the mongodb will validate the incoming data based on the schema we defined.
And either it accepts it and then allows the write to the database or it rejects the incoming data, hence your database is not touched and is not changed and the user gets an error.
You can also define which kinds of operations you want to validate and what you want to do if validation fails with two settings you can add.
You can define which document should get validated and what happens if it fails.
You can either set the validation level to strict which means all inserts and updates are checked.
Or to moderate which means all inserts are checked but updates are only checked for documents which were valid before.
So if you had some invalid data in there because it existed before you set up a schema, then you could still change these documents even if they don't fit your schema. 
For validation action, you can decide whether you want to throw an error and not go on with the insert or update.
So it will not change your database data.
Or if you only want to log a warning and proceed, so then you would still write the data.
You would still change the data but log a warning that it did not fulfill your criteria.

54
db.posts.drop()
Create the collection differently, not implicitly once we add something but explicitly.
If you want to configure your collection in a special way, well then you can use that create collection command.
db.createCollection("posts", {
  validator: {
    $jsonSchema: {
      bsonType: "object",
      required: ["title", "text", "creator", "comments"],
      properties: {
        title: {
          bsonType: "string",
          description: "must be a string and is required",
        },
        creator: {
          bsonType: "objectId",
          description: "must be an objectid and is required",
        },
        comments: {
          bsonType: "array",
          description: "must be an array and is required",
          items: {
            bsonType: "object",
            required: ["text", "author"],
            properties: {
              text: {
                bsonType: "string",
                description: "must be a string and is required",
              },
              author: {
                bsonType: "objectId",
                description: "must be an objectid and is required",
              },
            },
          },
        },
      },
    },
  },
});
db.posts.insertOne({ title: 'My first post!', text: 'This is my first post, i hope you like it!', tags: ['new', 'tech'], creator: ObjectId("62c28f36d1d2958fc09fa83a"), comments: [{ text: 'I like this post!', author: ObjectId("62c28f36d1d2958fc09fa839") }] })
db.posts.insertOne({ title: 'My first post!', text: 'This is my first post, i hope you like it!', tags: ['new', 'tech'], creator: ObjectId("62c28f36d1d2958fc09fa83a"), comments: [{ text: 'I like this post!', author: 12 }] })
db.posts.find().pretty()
There you first of all as a first argument to the create collection method define the name of the collection.
In our case, that would be posts, so previously you just accessed it and started working with it.
Now you create it and therefore you have to define the name here.
The second argument is a document where you can configure that collection and one important piece of configuration here is the validator.
The validator key takes another sub-document where you can now define a schema against which incoming data with insert or with inserts or updates has to validate.
You do this by adding a json schema key, $jsonschema key here, and then again another nested document and this now holds the schema.
So here we're just saying hey our validator is the json schema.
Historically there were other validators but it is strongly recommended to go with json schema now and then you define the schema here in this nested document.
Now there you can define a schema for every document which is added to the collection, for example we can set the bson type here to object.
So everything that gets added to the collection should be a valid document or object.
More interestingly, we can set a required key here which is an array and here, we can define names of fields in the document which will be part of that post collection that are absolutely required.
And if we try to add data that does not have these fields, we'll get an error or warning depending on our settings.
So here, we simply pass the names of the fields like in our case for the post here, you could say a title is required and a text is required, maybe tags are not required.
The creator is required though, so creator and the comments let's say are also required.
So now these four fields are required on every document that gets added to the post collection.
We can even dive a bit deeper and start working on our properties.
Now we can add a properties key which is another nested document where we can define for every property of every document that gets added to the post collection, how it should look like.

55
Validation works and it didn't add our incorrect post.
As a database administrator and this is how you would add such settings like validation.
You can use db.runCommand in the shell here to run, well administrative command.
You pass a document with information about the command.
And here, the command is that we set a collMod, that stands for collection modifier and we define the collection which we do want to modify.
Posts in my case and then we can again pass a validator.
db.runCommand({
  collMod: 'posts',
  validator: {
    $jsonSchema: {
      bsonType: 'object',
      required: ['title', 'text', 'creator', 'comments'],
      properties: {
        title: {
          bsonType: 'string',
          description: 'must be a string and is required'
        },
        text: {
          bsonType: 'string',
          description: 'must be a string and is required'
        },
        creator: {
          bsonType: 'objectId',
          description: 'must be an objectid and is required'
        },
        comments: {
          bsonType: 'array',
          description: 'must be an array and is required',
          items: {
            bsonType: 'object',
            required: ['text', 'author'],
            properties: {
              text: {
                bsonType: 'string',
                description: 'must be a string and is required'
              },
              author: {
                bsonType: 'objectId',
                description: 'must be an objectid and is required'
              }
            }
          }
        }
      }
    }
  },
  validationAction: 'warn'
});
I want to set a validation action here.
The default is error which blocks the action and throws an error, I'll set it to warn.
And now if I again tried to insert one post with my author being well or having a value of 12, which is not an objectId.
This actually succeeds and the only thing it did is it will have written a warning into our log file and the log file is stored on our system.
db.posts.insertOne({ title: 'My first post!', text: 'This is my first post, i hope you like it!', tags: ['new', 'tech'], creator: ObjectId("62c28f36d1d2958fc09fa83a"), comments: [{ text: 'I like this post!', author: 12 }] })
So this is the difference, now what you want to use here depends on your application and your requirements there.
It's good to know that you can configure these things and putting validation in place can make a lot of sense depending on how your application works.
How important it is for you to have one consistent scheme of data.
And you also now saw that you can define that validation schema when you create the collection or also thereafter with the help of run command.

56
How does your application or your data scientists, how do they need the data?
You want to store your data in a way that it's easy to fetch especially if you're building an app.
Or if you're having a use case where you fetch a lot because that's the next important question.
How often do you fetch data and how often do you change it?
Do you need to optimize for writes or for reads? Often it's for reads but it could be different for you. 
If you write your data a lot, you should definitely avoid duplicates, make sure you got no duplicates.
if you read a lot, maybe some duplicates are ok if these duplicates don't change that often.
Basically what I covered when walking three different relations setup options.
Also keep in mind how much data will you save and how big is it.
Do you store all citizens of New York City? Maybe embedding the data is not your best choice then. 
How is your data related in general, one-to-one, one-to-many, many-to-many?
This often gives an indication for whether you want to go with embedded documents or references and in general.
Will duplicates hurt you?
Do you update your data a lot in which you have to update a lot of duplicates?
Do you maybe have snapshot data like with orders and products where you don't care about updates to the most recent data to your products data?
And finally, will you hit any data or storage limits, like do you need to embed 100 levels deep which is the limit mongodb imposes?
It's not very likely but that is something you should at least be aware of and which you should keep in mind. 
With that, here's the general summary. In this module, we had a detailed look at how you model schemas, that this can make sense.
Even though mongodb does not enforce a schema onto you because your application typically needs data in a specific structure.
Important factors are the factors I just mentioned, frequency, relations, size and so on.
You also learned about data types there by the way, text, integers, long integers, decimals and I will also come back to the numbers later in this course.
We also had a detailed look at relations in this module, you basically have two options, embedding or references and you want to use embedded documents.
If you've got a one-to-one or one-to-many relationship and if it makes sense for your app and the way you interact with your data with all the points I highlighted.
References makes sense for many-to-many relationships or if you want to fetch data separated or if you got very large amounts of nested data.
Like New York City with all its citizens.
Exceptions are always possible and there is no hard rule, like many-to-many should always use references as you saw with the example of products and orders.
But keeping an eye on your app requirements and how your app works and interacts with your data gives you a good clue and indication of how you want to structure your data typically.
Last but not least in this module, we had a look at schema validation which allows you to enforce a certain set of rules on incoming data so that no invalid data ends up in your database.
You learned how you can define such rules and how that works with json schema and you also learned that you can configure how your rules are applied.
If actions get blocked or if they just get a warning logged to the log files.

57
Useful Resources & Links
Helpful Articles/ Docs:

The MongoDB Limits: https://docs.mongodb.com/manual/reference/limits/

The MongoDB Data Types: https://docs.mongodb.com/manual/reference/bson-types/

More on Schema Validation: https://docs.mongodb.com/manual/core/schema-validation/